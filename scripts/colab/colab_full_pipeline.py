"""
Colab MID ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ìŠ¤í¬ë¦½íŠ¸
HSG-Diffusion í•™ìŠµ ìë™í™”
"""

import argparse
import sys
import yaml
import torch
from pathlib import Path

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ì¶”ê°€
project_root = Path(__file__).parent.parent.parent
sys.path.insert(0, str(project_root))


def main():
    parser = argparse.ArgumentParser(description="Colab MID íŒŒì´í”„ë¼ì¸")
    parser.add_argument(
        "--mode",
        type=str,
        default="fast",
        choices=["fast", "standard"],
        help="í•™ìŠµ ëª¨ë“œ",
    )
    parser.add_argument(
        "--data_dir",
        type=str,
        default="/content/Roundabout_AI/data/sdd/converted",
        help="ë³€í™˜ëœ ë°ì´í„° ë””ë ‰í† ë¦¬",
    )
    parser.add_argument(
        "--output_dir",
        type=str,
        default="/content/Roundabout_AI/data/processed",
        help="ì „ì²˜ë¦¬ ê²°ê³¼ ì €ì¥ ë””ë ‰í† ë¦¬",
    )
    parser.add_argument(
        "--config",
        type=str,
        default=None,
        help="ì„¤ì • íŒŒì¼ ê²½ë¡œ (Noneì´ë©´ modeì— ë”°ë¼ ìë™ ì„ íƒ)",
    )

    args = parser.parse_args()

    print("=" * 80)
    print("HSG-Diffusion Colab ìë™í™” íŒŒì´í”„ë¼ì¸")
    print("=" * 80)

    # 1. ì„¤ì • ë¡œë“œ
    print("\n[1/6] ì„¤ì • ë¡œë“œ...")
    if args.config:
        config_file = Path(args.config)
    else:
        config_file = project_root / f"configs/mid_config_{args.mode}.yaml"

    if not config_file.exists():
        print(f"âš ï¸  ì„¤ì • íŒŒì¼ ì—†ìŒ: {config_file}")
        print("ê¸°ë³¸ ì„¤ì • ì‚¬ìš©")
        config = {
            "model": {
                "obs_steps": 30,
                "pred_steps": 50,
                "hidden_dim": 128 if args.mode == "fast" else 256,
                "num_diffusion_steps": 50 if args.mode == "fast" else 100,
                "node_features": 9,
            },
            "data": {
                "batch_size": 16 if args.mode == "fast" else 32,
                "train_ratio": 0.7,
                "val_ratio": 0.15,
                "test_ratio": 0.15,
            },
            "training": {
                "num_epochs": 20 if args.mode == "fast" else 100,
                "optimizer": "adamw",
                "learning_rate": 0.001,
                "use_amp": True,
            },
            "evaluation": {"num_samples": 20, "ddim_steps": 2},
        }
    else:
        with open(config_file, "r") as f:
            config = yaml.safe_load(f)
    print(f"  âœ“ ì„¤ì •: {config_file}")

    # 2. ë°ì´í„° ì „ì²˜ë¦¬
    print("\n[2/6] ë°ì´í„° ì „ì²˜ë¦¬...")
    from src.data_processing.preprocessor import TrajectoryPreprocessor
    from src.integration.sdd_data_adapter import SDDDataAdapter
    import pandas as pd
    import pickle

    data_dir = Path(args.data_dir)
    output_dir = Path(args.output_dir)
    output_dir.mkdir(parents=True, exist_ok=True)

    # ë°ì´í„° ë¡œë“œ
    all_data = []
    for csv_file in sorted(data_dir.glob("*.csv")):
        df = pd.read_csv(csv_file)
        all_data.append(df)

    combined_df = pd.concat(all_data, ignore_index=True)
    print(f"  âœ“ ë°ì´í„° ë¡œë“œ: {len(combined_df):,}í–‰")

    # ì—ì´ì „íŠ¸ íƒ€ì… í™•ì¸
    if "agent_type" in combined_df.columns:
        agent_types = combined_df["agent_type"].unique()
        print(f"  âœ“ ì—ì´ì „íŠ¸ íƒ€ì…: {list(agent_types)}")

    # ìƒ˜í”Œë§ (Fast ëª¨ë“œ)
    if args.mode == "fast":
        import numpy as np

        sample_ratio = 0.3
        unique_tracks = combined_df["track_id"].unique()
        sampled_tracks = np.random.choice(
            unique_tracks, size=int(len(unique_tracks) * sample_ratio), replace=False
        )
        combined_df = combined_df[combined_df["track_id"].isin(sampled_tracks)]
        print(f"  âœ“ ìƒ˜í”Œë§: {len(combined_df):,}í–‰ ({sample_ratio*100:.0f}%)")

    # ì „ì²˜ë¦¬
    preprocessor = TrajectoryPreprocessor(
        obs_window=config["model"]["obs_steps"],
        pred_window=config["model"]["pred_steps"],
        sampling_rate=10.0,
    )

    windows = preprocessor.create_sliding_windows(combined_df)
    print(f"  âœ“ ìœˆë„ìš° ìƒì„±: {len(windows)}ê°œ")

    # ì €ì¥
    with open(output_dir / "sdd_windows.pkl", "wb") as f:
        pickle.dump(windows, f)
    print(f"  âœ“ ì €ì¥ ì™„ë£Œ: {output_dir / 'sdd_windows.pkl'}")

    # 3. ë°ì´í„° ë¡œë” ìƒì„± (ì”¬ ê·¸ë˜í”„ í¬í•¨)
    print("\n[3/6] ë°ì´í„° ë¡œë” ìƒì„±...")
    from src.training.data_loader import (
        TrajectoryDataset,
        create_dataloader,
        split_dataset,
    )
    from src.scene_graph.scene_graph_builder import SceneGraphBuilder

    # ì”¬ ê·¸ë˜í”„ ë¹Œë” ìƒì„±
    scene_graph_builder = SceneGraphBuilder(spatial_threshold=20.0)
    print("  âœ“ ì”¬ ê·¸ë˜í”„ ë¹Œë” ìƒì„±")

    train_windows, val_windows, test_windows = split_dataset(
        windows,
        train_ratio=config["data"].get("train_ratio", 0.7),
        val_ratio=config["data"].get("val_ratio", 0.15),
        test_ratio=config["data"].get("test_ratio", 0.15),
    )

    # ì”¬ ê·¸ë˜í”„ ë¹Œë”ë¥¼ ë°ì´í„°ì…‹ì— ì „ë‹¬
    train_dataset = TrajectoryDataset(
        train_windows, scene_graph_builder=scene_graph_builder, use_scene_graph=True
    )
    val_dataset = TrajectoryDataset(
        val_windows, scene_graph_builder=scene_graph_builder, use_scene_graph=True
    )

    batch_size = config["data"].get("batch_size", 32)
    train_loader = create_dataloader(train_dataset, batch_size=batch_size)
    val_loader = create_dataloader(val_dataset, batch_size=batch_size, shuffle=False)

    print(f"  âœ“ í•™ìŠµ ë°ì´í„°: {len(train_windows)}ê°œ")
    print(f"  âœ“ ê²€ì¦ ë°ì´í„°: {len(val_windows)}ê°œ")

    # 4. MID ëª¨ë¸ ìƒì„± âœ…
    print("\n[4/6] MID ëª¨ë¸ ìƒì„±...")
    from src.models.mid_integrated import create_fully_integrated_mid

    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    print(f"  ë””ë°”ì´ìŠ¤: {device}")

    model = create_fully_integrated_mid(
        obs_steps=config["model"]["obs_steps"],
        pred_steps=config["model"]["pred_steps"],
        hidden_dim=config["model"]["hidden_dim"],
        num_diffusion_steps=config["model"]["num_diffusion_steps"],
        node_features=config["model"]["node_features"],
        use_safety=True,
        node_types=["car", "pedestrian", "biker", "skater", "cart", "bus"],
    )
    model = model.to(device)

    print(f"  âœ“ MID ëª¨ë¸ ìƒì„± ì™„ë£Œ")
    print(f"    íŒŒë¼ë¯¸í„° ìˆ˜: {sum(p.numel() for p in model.parameters()):,}")

    # 5. MID Trainerë¡œ í•™ìŠµ âœ…
    print("\n[5/6] í•™ìŠµ ì‹œì‘...")
    from src.training.mid_trainer import MIDTrainer

    trainer = MIDTrainer(
        model=model,
        train_loader=train_loader,
        val_loader=val_loader,
        config=config["training"],
        device=device,
    )

    num_epochs = config["training"]["num_epochs"]
    trainer.train(num_epochs)

    # 6. í‰ê°€ (Diffusion ì§€í‘œ í¬í•¨) âœ…
    print("\n[6/6] í‰ê°€...")
    from src.evaluation.diffusion_metrics import DiffusionEvaluator

    evaluator = DiffusionEvaluator(k=config["evaluation"]["num_samples"])

    model.eval()
    all_samples = []
    all_ground_truths = []

    with torch.no_grad():
        for batch_idx, batch in enumerate(val_loader):
            if isinstance(batch, dict):
                obs_data = batch.get("obs_data", batch.get("obs_trajectory"))
                future_data = batch.get("future_data", batch.get("future_trajectory"))
                hetero_graph = batch.get("hetero_graph")
            else:
                obs_data = batch[0]
                future_data = batch[1] if len(batch) > 1 else None
                hetero_graph = batch[2] if len(batch) > 2 else None

            if obs_data is not None:
                obs_data = obs_data.to(device)
            if future_data is not None:
                future_data = future_data.to(device)
            if hetero_graph is not None:
                hetero_graph = hetero_graph.to(device)

            # ìƒ˜í”Œë§
            result = model.sample(
                hetero_data=hetero_graph,
                obs_trajectory=obs_data[:, :, :2] if obs_data is not None else None,
                num_samples=config["evaluation"]["num_samples"],
                ddim_steps=config["evaluation"]["ddim_steps"],
                use_safety_filter=True,
            )

            if isinstance(result, dict):
                samples = result.get("safe_samples", result.get("samples"))
            else:
                samples = result

            if samples is not None and future_data is not None:
                all_samples.append(samples.detach().cpu().numpy())
                all_ground_truths.append(future_data.detach().cpu().numpy())

            if batch_idx >= 10:  # ì²˜ìŒ 10ê°œ ë°°ì¹˜ë§Œ í‰ê°€
                break

    if all_samples and all_ground_truths:
        import numpy as np

        samples_np = np.concatenate(
            all_samples, axis=1
        )  # [num_samples, total_batch, pred_steps, 2]
        ground_truths_np = np.concatenate(
            all_ground_truths, axis=0
        )  # [total_batch, pred_steps, 2]

        metrics = evaluator.evaluate(samples_np, ground_truths_np)

        print(f"\nğŸ“Š í‰ê°€ ê²°ê³¼:")
        print(f"  Min ADE: {metrics.get('min_ade', 0):.4f} m")
        print(f"  Min FDE: {metrics.get('min_fde', 0):.4f} m")
        print(f"  Diversity: {metrics.get('diversity', 0):.4f}")
        print(f"  Coverage: {metrics.get('coverage', 0):.4f}")
        print(f"  Collision Rate: {metrics.get('collision_rate', 0):.4f}")

    print("\n" + "=" * 80)
    print("âœ“ HSG-Diffusion í•™ìŠµ ì™„ë£Œ!")
    print("=" * 80)


if __name__ == "__main__":
    main()
