"""
ìë™ í˜¸ëª¨ê·¸ë˜í”¼ ì¶”ì • ìŠ¤í¬ë¦½íŠ¸
OpenCV SIFT/ORBë¥¼ ì‚¬ìš©í•˜ì—¬ ìë™ìœ¼ë¡œ íŠ¹ì§•ì  ë§¤ì¹­ ë° í˜¸ëª¨ê·¸ë˜í”¼ ê³„ì‚°
í•˜ë£¨ ë‚´ ì™„ë£Œ ëª©í‘œ: ìˆ˜ë™ ì‘ì—… ìµœì†Œí™”
"""

import numpy as np
from pathlib import Path
from typing import Tuple, Optional
import json

# OpenCVëŠ” ì„ íƒì  (SIFT/ORB ì‚¬ìš© ì‹œë§Œ í•„ìš”)
try:
    import cv2
    HAS_OPENCV = True
except ImportError:
    HAS_OPENCV = False


class AutoHomographyEstimator:
    """ìë™ í˜¸ëª¨ê·¸ë˜í”¼ ì¶”ì • í´ë˜ìŠ¤"""

    def __init__(self, method='SIFT'):
        """
        Args:
            method: 'SIFT' ë˜ëŠ” 'ORB' (SIFTê°€ ë” ì •í™•í•˜ì§€ë§Œ ëŠë¦¼)
        """
        self.method = method

        if method == 'SIFT':
            self.detector = cv2.SIFT_create()
            self.matcher = cv2.BFMatcher()
        else:  # ORB
            self.detector = cv2.ORB_create()
            self.matcher = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True)

    def extract_features(self, image: np.ndarray) -> Tuple[np.ndarray, np.ndarray]:
        """
        ì´ë¯¸ì§€ì—ì„œ íŠ¹ì§•ì  ì¶”ì¶œ

        Args:
            image: ì…ë ¥ ì´ë¯¸ì§€ (BGR)

        Returns:
            (keypoints, descriptors)
        """
        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY) if len(image.shape) == 3 else image
        keypoints, descriptors = self.detector.detectAndCompute(gray, None)
        return keypoints, descriptors

    def match_features(
        self,
        desc1: np.ndarray,
        desc2: np.ndarray,
        ratio_thresh: float = 0.75
    ) -> list:
        """
        íŠ¹ì§•ì  ë§¤ì¹­

        Args:
            desc1: ì²« ë²ˆì§¸ ì´ë¯¸ì§€ì˜ ë””ìŠ¤í¬ë¦½í„°
            desc2: ë‘ ë²ˆì§¸ ì´ë¯¸ì§€ì˜ ë””ìŠ¤í¬ë¦½í„°
            ratio_thresh: Lowe's ratio test ì„ê³„ê°’

        Returns:
            ë§¤ì¹­ëœ íŠ¹ì§•ì  ë¦¬ìŠ¤íŠ¸
        """
        if self.method == 'SIFT':
            # Lowe's ratio test
            matches = self.matcher.knnMatch(desc1, desc2, k=2)
            good_matches = []
            for match_pair in matches:
                if len(match_pair) == 2:
                    m, n = match_pair
                    if m.distance < ratio_thresh * n.distance:
                        good_matches.append(m)
        else:  # ORB
            matches = self.matcher.match(desc1, desc2)
            good_matches = sorted(matches, key=lambda x: x.distance)[:50]

        return good_matches

    def estimate_homography(
        self,
        img1: np.ndarray,
        img2: np.ndarray,
        min_matches: int = 10
    ) -> Tuple[Optional[np.ndarray], int, np.ndarray]:
        """
        ë‘ ì´ë¯¸ì§€ ê°„ í˜¸ëª¨ê·¸ë˜í”¼ ì¶”ì •

        Args:
            img1: ì²« ë²ˆì§¸ ì´ë¯¸ì§€ (SDD ë¹„ë””ì˜¤ í”„ë ˆì„)
            img2: ë‘ ë²ˆì§¸ ì´ë¯¸ì§€ (ìœ„ì„± ì§€ë„ ë˜ëŠ” ì°¸ì¡° ì´ë¯¸ì§€)
            min_matches: ìµœì†Œ ë§¤ì¹­ ì  ìˆ˜

        Returns:
            (í˜¸ëª¨ê·¸ë˜í”¼ í–‰ë ¬, ë§¤ì¹­ ì  ìˆ˜, ë§¤ì¹­ ì‹œê°í™” ì´ë¯¸ì§€)
        """
        # íŠ¹ì§•ì  ì¶”ì¶œ
        kp1, desc1 = self.extract_features(img1)
        kp2, desc2 = self.extract_features(img2)

        if desc1 is None or desc2 is None:
            return None, 0, img1

        # íŠ¹ì§•ì  ë§¤ì¹­
        matches = self.match_features(desc1, desc2)

        if len(matches) < min_matches:
            print(f"âš ï¸  ë§¤ì¹­ ì  ë¶€ì¡±: {len(matches)}ê°œ (ìµœì†Œ {min_matches}ê°œ í•„ìš”)")
            return None, len(matches), img1

        # ë§¤ì¹­ ì  ì¢Œí‘œ ì¶”ì¶œ
        src_pts = np.float32([kp1[m.queryIdx].pt for m in matches]).reshape(-1, 1, 2)
        dst_pts = np.float32([kp2[m.trainIdx].pt for m in matches]).reshape(-1, 1, 2)

        # RANSACìœ¼ë¡œ í˜¸ëª¨ê·¸ë˜í”¼ ì¶”ì •
        H, mask = cv2.findHomography(
            src_pts,
            dst_pts,
            cv2.RANSAC,
            ransacReprojThreshold=5.0
        )

        # ë§¤ì¹­ ì‹œê°í™”
        matches_img = cv2.drawMatches(
            img1, kp1, img2, kp2,
            [matches[i] for i in range(len(matches)) if mask[i]],
            None,
            flags=cv2.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS
        )

        inliers = int(mask.sum())
        print(f"âœ“ í˜¸ëª¨ê·¸ë˜í”¼ ì¶”ì • ì™„ë£Œ: {inliers}/{len(matches)} inliers")

        return H, inliers, matches_img

    def estimate_from_known_points(
        self,
        src_points: np.ndarray,
        dst_points: np.ndarray
    ) -> Optional[np.ndarray]:
        """
        ì•Œë ¤ì§„ ëŒ€ì‘ì ìœ¼ë¡œë¶€í„° í˜¸ëª¨ê·¸ë˜í”¼ ì¶”ì • (ê°€ì¥ ë¹ ë¥¸ ë°©ë²•)

        Args:
            src_points: í”½ì…€ ì¢Œí‘œ (N, 2)
            dst_points: ë¯¸í„° ì¢Œí‘œ (N, 2)

        Returns:
            í˜¸ëª¨ê·¸ë˜í”¼ í–‰ë ¬
        """
        if len(src_points) < 4:
            raise ValueError("ìµœì†Œ 4ê°œì˜ ëŒ€ì‘ì  í•„ìš”")

        H, mask = cv2.findHomography(
            src_points.reshape(-1, 1, 2),
            dst_points.reshape(-1, 1, 2),
            cv2.RANSAC,
            ransacReprojThreshold=1.0
        )

        return H


def load_sdd_frame(video_path: Path, frame_idx: int = 0) -> Optional[np.ndarray]:
    """SDD ë¹„ë””ì˜¤ì—ì„œ í”„ë ˆì„ ì¶”ì¶œ"""
    if not video_path.exists():
        return None

    cap = cv2.VideoCapture(str(video_path))
    cap.set(cv2.CAP_PROP_POS_FRAMES, frame_idx)
    ret, frame = cap.read()
    cap.release()

    return frame if ret else None


def estimate_scale_from_reference(
    pixel_coords: np.ndarray,
    known_distance_pixels: float,
    known_distance_meters: float
) -> Tuple[float, float]:
    """
    ì•Œë ¤ì§„ ê±°ë¦¬ë¡œë¶€í„° ìŠ¤ì¼€ì¼ íŒ©í„° ì¶”ì • (ê°€ì¥ ê°„ë‹¨í•œ ë°©ë²•)

    Args:
        pixel_coords: í”½ì…€ ì¢Œí‘œ
        known_distance_pixels: í”½ì…€ ë‹¨ìœ„ ì•Œë ¤ì§„ ê±°ë¦¬ (ì˜ˆ: ì°¨ì„  í­)
        known_distance_meters: ë¯¸í„° ë‹¨ìœ„ ì•Œë ¤ì§„ ê±°ë¦¬ (ì˜ˆ: 3.0m)

    Returns:
        (scale_x, scale_y)
    """
    scale = known_distance_meters / known_distance_pixels
    return scale, scale


def quick_homography_for_sdd():
    """
    SDD Death Circleìš© ë¹ ë¥¸ í˜¸ëª¨ê·¸ë˜í”¼ ì¶”ì •
    íšŒì „êµì°¨ë¡œ ì¤‘ì‹¬ì ê³¼ ì•Œë ¤ì§„ ê±°ë¦¬ë¡œë¶€í„° ì¶”ì •
    OpenCV ë¶ˆí•„ìš” - ìˆœìˆ˜ NumPyë§Œ ì‚¬ìš©
    """
    # SDD Death Circle ëŒ€ëµì  í¬ê¸°
    # íšŒì „êµì°¨ë¡œ ì§ê²½: ì•½ 20-30m
    # ì´ë¯¸ì§€ í¬ê¸°: ì•½ 1400x1900 í”½ì…€

    # ë°©ë²• 1: ê°„ë‹¨í•œ ìŠ¤ì¼€ì¼ë§ (ì´ë¯¸ êµ¬í˜„ë¨)
    scale_x = 30.0 / 1400.0
    scale_y = 40.0 / 1900.0

    # ë°©ë²• 2: íšŒì „êµì°¨ë¡œ ì¤‘ì‹¬ì  ê¸°ì¤€ ë³€í™˜
    # ì¤‘ì‹¬ì : (700, 950) í”½ì…€ â†’ (0, 0) ë¯¸í„°
    center_pixel = np.array([700, 950])
    center_meter = np.array([0, 0])

    # ì•„í•€ ë³€í™˜ í–‰ë ¬ (íšŒì „ ì—†ìŒ, ìŠ¤ì¼€ì¼ë§Œ)
    H_affine = np.array([
        [scale_x, 0, -center_pixel[0] * scale_x + center_meter[0]],
        [0, scale_y, -center_pixel[1] * scale_y + center_meter[1]],
        [0, 0, 1]
    ])

    return H_affine


def save_homography(H: np.ndarray, output_path: Path):
    """í˜¸ëª¨ê·¸ë˜í”¼ í–‰ë ¬ ì €ì¥"""
    output_path.parent.mkdir(parents=True, exist_ok=True)
    np.savetxt(output_path, H, fmt='%.8f')
    print(f"âœ“ í˜¸ëª¨ê·¸ë˜í”¼ ì €ì¥: {output_path}")


def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    import argparse

    parser = argparse.ArgumentParser(description='ìë™ í˜¸ëª¨ê·¸ë˜í”¼ ì¶”ì •')
    parser.add_argument('--method', choices=['SIFT', 'ORB', 'quick'], default='quick',
                       help='ì¶”ì • ë°©ë²• (quick: ê°€ì¥ ë¹ ë¦„, SIFT: ê°€ì¥ ì •í™•)')
    parser.add_argument('--video', type=str, help='SDD ë¹„ë””ì˜¤ ê²½ë¡œ')
    parser.add_argument('--satellite', type=str, help='ìœ„ì„± ì§€ë„ ì´ë¯¸ì§€ ê²½ë¡œ')
    parser.add_argument('--output', type=str, default='data/sdd/homography/H.txt',
                       help='ì¶œë ¥ ê²½ë¡œ')

    args = parser.parse_args()

    if args.method == 'quick':
        # ê°€ì¥ ë¹ ë¥¸ ë°©ë²•: ì•Œë ¤ì§„ ìŠ¤ì¼€ì¼ ì‚¬ìš©
        print("ğŸš€ ë¹ ë¥¸ í˜¸ëª¨ê·¸ë˜í”¼ ì¶”ì • (ìŠ¤ì¼€ì¼ ê¸°ë°˜)...")
        H = quick_homography_for_sdd()
        save_homography(H, Path(args.output))
        print("âœ“ ì™„ë£Œ! (ì•½ 1ë¶„ ì†Œìš”)")

    elif args.video and args.satellite:
        # ìë™ íŠ¹ì§•ì  ë§¤ì¹­
        if not HAS_OPENCV:
            print("âŒ OpenCVê°€ í•„ìš”í•©ë‹ˆë‹¤. ì„¤ì¹˜: pip install opencv-python")
            return

        print(f"ğŸ” {args.method} íŠ¹ì§•ì  ë§¤ì¹­ ì¤‘...")

        estimator = AutoHomographyEstimator(method=args.method)

        img1 = cv2.imread(args.video) if Path(args.video).suffix in ['.jpg', '.png'] else load_sdd_frame(Path(args.video))
        img2 = cv2.imread(args.satellite)

        if img1 is None or img2 is None:
            print("âŒ ì´ë¯¸ì§€ ë¡œë“œ ì‹¤íŒ¨")
            return

        H, num_matches, matches_img = estimator.estimate_homography(img1, img2)

        if H is not None:
            save_homography(H, Path(args.output))
            cv2.imwrite(str(Path(args.output).parent / 'matches.jpg'), matches_img)
            print(f"âœ“ ì™„ë£Œ! ({num_matches}ê°œ ë§¤ì¹­)")
        else:
            print("âŒ í˜¸ëª¨ê·¸ë˜í”¼ ì¶”ì • ì‹¤íŒ¨")

    else:
        print("ì‚¬ìš©ë²•:")
        print("  ë¹ ë¥¸ ë°©ë²•: python scripts/auto_homography_estimation.py --method quick")
        print("  ìë™ ë§¤ì¹­: python scripts/auto_homography_estimation.py --method SIFT --video <ë¹„ë””ì˜¤> --satellite <ìœ„ì„±ì§€ë„>")


if __name__ == "__main__":
    main()

