# **SDD 'Death Circle' 내 이기종 혼합 교통 상호작용 예측을 위한 시맨틱 씬 그래프 및 Spatio-Temporal Heterogeneous GNN 기반 통합 연구 계획서**

## **1\. 총괄 요약 (Executive Summary)**

자율 주행 시스템과 지능형 교통 시스템(ITS)의 발전에도 불구하고, 비정형적이고 혼잡한 환경에서의 이동체 경로 예측(Trajectory Prediction)은 여전히 난제로 남아 있습니다. 특히 스탠포드 드론 데이터셋(Stanford Drone Dataset, SDD)의 'Death Circle'과 같은 회전 교차로는 차량, 보행자, 자전거, 스케이트보더 등 다양한 동적 특성을 가진 에이전트들이 복잡한 사회적 상호작용(Social Interaction)을 통해 이동하는 고엔트로피 환경입니다.1 기존의 동질적(Homogeneous) 모델링 접근법은 에이전트 간의 기하학적, 물리적 차이를 충분히 반영하지 못해 충돌 위험도가 높은 상황에서의 예측 정밀도가 떨어지는 한계가 있습니다.

본 연구 계획서는 이러한 한계를 극복하기 위해 \*\*시맨틱 씬 그래프(Semantic Scene Graph)\*\*와 \*\*이기종 그래프 신경망(Heterogeneous Graph Neural Network)\*\*을 결합한 새로운 예측 프레임워크를 제안합니다. 구체적으로는 공간적 상호작용을 모델링하기 위한 \*\*Heterogeneous Graph Attention Network (HeteroGAT)\*\*와 시간적 진화를 포착하기 위한 \*\*Attention Temporal Graph Convolutional Network (A3TGCN)\*\*의 하이브리드 아키텍처를 설계합니다.3

본 보고서는 데이터 전처리부터 최종 결과 시각화에 이르는 전체 연구 로드맵을 포괄적으로 제시합니다. 특히 SDD 데이터셋의 한계점인 픽셀 좌표계를 미터법 좌표계로 변환하기 위한 **호모그래피(Homography) 추정 및 기하학적 보정 프로토콜**을 상세히 수립하고 6, 신경망 모델의 예측 결과를 보완하기 위한 \*\*Plan B(안전 지표 분석)\*\*로서 TTC(Time-to-Collision) 및 PET(Post-Encroachment Time) 기반의 위험도 평가 레이어를 구축합니다.8 본 연구는 단순한 위치 예측을 넘어, 에이전트 간의 이질적인 상호작용 메커니즘을 규명하고 실제 주행 안전성을 담보할 수 있는 해석 가능한 예측 모델을 목표로 합니다.

## ---

**2\. 서론 및 문제 정의 (Introduction and Problem Definition)**

### **2.1 연구 배경: 혼합 교통 환경의 복잡성**

현대의 도심 환경은 차량 전용 도로와 달리 보행자, 자전거, 퍼스널 모빌리티(PM) 등이 혼재된 '혼합 교통(Mixed Traffic)' 양상을 띱니다. 스탠포드 캠퍼스의 'Death Circle'은 이러한 혼합 교통의 극단적인 예시로, 명확한 신호 체계보다는 에이전트 간의 눈치싸움, 즉 '사회적 감수성(Social Sensitivity)'에 의해 통행 우선권이 결정되는 회전 교차로입니다.1 이 환경에서 자전거는 차량보다 민첩하지만 보행자보다는 빠르며, 차량은 강력한 물리적 위협을 가하지만 도로 규제에 종속되는 등 각 에이전트는 고유한 운동학적 제약과 상호작용 규칙을 가집니다.

기존의 Social LSTM이나 Social GAN과 같은 초기 연구들은 모든 에이전트를 동일한 점 질량(Point Mass)으로 취급하거나, 단순히 거리 기반의 풀링(Pooling)을 수행하여 에이전트의 타입(Type)에 따른 상호작용의 이질성을 무시하는 경향이 있었습니다.5 예를 들어, 보행자가 다가오는 자전거를 피하는 방식과 다가오는 버스를 피하는 방식은 근본적으로 다르지만, 동질적 그래프 모델은 이를 구분하여 학습하기 어렵습니다.

### **2.2 연구 목표 및 범위**

본 연구의 핵심 목표는 **이기종 에이전트 간의 상호작용을 명시적으로 모델링하는 이기종 그래프 신경망(Heterogeneous GNN) 기반의 경로 예측 시스템**을 개발하는 것입니다.

**세부 목표:**

1. **정밀한 데이터 전처리:** SDD의 픽셀 좌표를 실제 물리적 거리를 반영한 미터 좌표계로 변환하기 위한 강건한 호모그래피 매트릭스($H$) 산출.6  
2. **시맨틱 씬 그래프 구축:** 매 프레임마다 에이전트(노드)와 상호작용(엣지)의 타입이 정의된 동적 그래프 생성.12  
3. **Spatio-Temporal 모델링:** 에이전트 타입별로 다른 어텐션 가중치를 학습하는 HeteroGAT와 시계열 패턴을 학습하는 A3TGCN의 결합.3  
4. **안전성 평가(Plan B):** 예측된 경로의 불확실성을 고려하여 TTC, PET 등 물리적 충돌 위험 지표를 산출하고 시각화.8

## ---

**3\. 문헌 연구 및 이론적 배경 (Literature Review)**

### **3.1 경로 예측 모델의 진화**

경로 예측 기술은 칼만 필터(Kalman Filter)와 같은 물리 기반 모델에서 데이터 기반의 딥러닝 모델로 발전해 왔습니다.

| 모델 구분 | 대표 알고리즘 | 특징 및 한계점 |
| :---- | :---- | :---- |
| **초기 RNN 기반** | Social LSTM | 에이전트 간 상호작용을 소셜 풀링(Social Pooling)으로 해결했으나, 그리드 기반의 고정된 구조로 인해 유연성이 부족함. |
| **생성 모델 기반** | Social GAN 10 | GAN을 도입하여 다중 모달(Multi-modal) 예측을 수행. 그러나 에이전트 간의 관계를 단순 거리로만 판단하며 이기종성을 고려하지 않음. |
| **그래프 기반** | Trajectron++ 16 | 시공간 그래프를 도입하고 에이전트의 역학(Dynamics)을 고려하기 시작했으나, 엣지 타입에 따른 메시지 패싱의 세분화가 부족함. |
| **이기종 그래프** | **본 연구 제안 (ST-HGNN)** | 에이전트 타입별로 서로 다른 엣지 관계(Relation)를 정의하고, GAT와 A3TGCN을 결합하여 관계별 가중치와 시간적 중요도를 동시에 학습함.5 |

### **3.2 씬 그래프(Scene Graph)와 의미론적 추론**

씬 그래프는 이미지 내 객체(Object)를 노드로, 객체 간의 관계(Relationship)를 엣지로 표현하는 구조화된 데이터입니다.12 컴퓨터 비전 분야(Visual Genome 등)에서 주로 사용되던 씬 그래프를 경로 예측에 도입함으로써, 단순한 "A와 B가 가깝다"는 정보가 아닌 "A(자전거)가 B(보행자)를 추월 중이다"와 같은 의미론적 맥락을 모델에 주입할 수 있습니다.13 본 연구에서는 이를 동적으로 확장하여, 매 시간 스텝마다 변화하는 위상 구조를 가진 **Dynamic Heterogeneous Scene Graph**를 정의합니다.

### **3.3 그래프 신경망과 시간적 주의 메커니즘**

동적 그래프 처리를 위해 PyTorch Geometric Temporal과 같은 라이브러리가 활용됩니다.19 특히 A3TGCN(Attention Temporal Graph Convolutional Network)은 TCN(Temporal Convolutional Network)에 어텐션 메커니즘을 결합하여, 긴 시퀀스 내에서 예측에 중요한 시간적 프레임(예: 방향 전환 직전의 순간)에 가중치를 부여할 수 있어 교통 흐름 예측에 탁월한 성능을 보입니다.4

## ---

**4\. 데이터셋 분석 및 전처리: 물리적 공간으로의 매핑 (Data Preprocessing)**

### **4.1 Stanford Drone Dataset (SDD) 및 Death Circle 특성**

SDD는 대학 캠퍼스 상공에서 드론으로 촬영된 데이터셋으로, 8개의 장소(Scene)에서 수집된 60여 개의 비디오로 구성됩니다.1 그중 'Death Circle'은 라운드어바웃 구조로, Pedestrian, Biker, Skater, Cart, Car, Bus 등 6가지 클래스가 혼재되어 있습니다.1

데이터셋의 원본 주석(Annotation)은 픽셀 좌표 $(x\_{pix}, y\_{pix})$로 제공됩니다. 그러나 실제 물리적 상호작용(속도, 가속도, 충돌 시간 등)을 모델링하기 위해서는 이를 미터법 좌표 $(x\_{met}, y\_{met})$로 변환해야 합니다. SDD는 일부 장소에 대해 호모그래피 행렬을 제공하지 않거나 불명확한 경우가 많아 11, 본 연구에서는 자체적인 호모그래피 추정 파이프라인을 수립합니다.

### **4.2 호모그래피(Homography) 추정 및 변환 로드맵**

픽셀 좌표계를 월드 좌표계(미터)로 변환하기 위해 평면 호모그래피 변환을 적용합니다. 이는 두 평면 사이의 투영 변환(Projective Transformation) 관계를 정의합니다.6

수식적 정의:

$$s \\begin{bmatrix} x' \\\\ y' \\\\ 1 \\end{bmatrix} \= H \\begin{bmatrix} x \\\\ y \\\\ 1 \\end{bmatrix} \= \\begin{bmatrix} h\_{11} & h\_{12} & h\_{13} \\\\ h\_{21} & h\_{22} & h\_{23} \\\\ h\_{31} & h\_{32} & h\_{33} \\end{bmatrix} \\begin{bmatrix} x \\\\ y \\\\ 1 \\end{bmatrix}$$

여기서 $(x, y)$는 이미지 픽셀 좌표, $(x', y')$는 월드 미터 좌표이며, $H$는 8 자유도를 가진 $3 \\times 3$ 행렬입니다 ($h\_{33}=1$로 정규화).6  
**실행 계획 (Step-by-Step):**

1. 위성 지도 확보 (Reference Map Acquisition):  
   구글 어스(Google Earth) 또는 QGIS를 활용하여 스탠포드 Death Circle 지역의 고해상도 위성 사진을 확보합니다. 이 위성 사진은 스케일 바(Scale Bar)를 포함하고 있어 실제 거리를 측정할 수 있는 Ground Truth 역할을 합니다.22  
2. 대응점(Correspondence Points) 추출:  
   SDD 영상의 첫 프레임과 위성 사진에서 공통적으로 식별 가능한 랜드마크(GCP: Ground Control Points)를 최소 4개 이상, 권장 8개 이상 선정합니다.6  
   * *선정 후보:* 회전 교차로의 중심점, 보도블록의 모서리, 도로의 페인트 마킹 끝점 등.  
   * *좌표 쌍 구성:* $P\_{img} \= \\{(u\_i, v\_i)\\}$ (픽셀), $P\_{world} \= \\{(X\_i, Y\_i)\\}$ (미터).  
3. DLT(Direct Linear Transformation) 알고리즘 적용:  
   각 점 $i$에 대해 다음의 선형 방정식을 유도합니다.

   $$\\begin{cases} \-h\_{11}u\_i \- h\_{12}v\_i \- h\_{13} \+ h\_{31}u\_i X\_i \+ h\_{32}v\_i X\_i \+ h\_{33}X\_i \= 0 \\\\ \-h\_{21}u\_i \- h\_{22}v\_i \- h\_{23} \+ h\_{31}u\_i Y\_i \+ h\_{32}v\_i Y\_i \+ h\_{33}Y\_i \= 0 \\end{cases}$$

   이를 $Ah=0$ 형태의 행렬식으로 구성하고, SVD(Singular Value Decomposition)를 수행하여 $A^TA$의 최소 고유값에 대응하는 고유벡터를 찾아 $H$를 추정합니다.21  
   * *구현 도구:* cv2.findHomography(pts\_src, pts\_dst, cv2.RANSAC)  
4. 검증 및 오차 보정:  
   추정된 $H$를 검증하기 위해 영상 내에서 실제 길이가 알려진 객체(예: 표준 차선 폭 3.0m, 횡단보도 길이)를 역투영하여 오차를 측정합니다. 오차가 허용 범위(예: \< 0.3m) 이내가 될 때까지 GCP를 조정합니다.

### **4.3 데이터 정제 및 특징 추출 (Feature Extraction)**

변환된 미터 좌표를 기반으로 학습에 필요한 동적 특징을 추출합니다.

* **이상치 제거:** lost 플래그가 있거나 occluded 상태가 5 프레임 이상 지속되는 궤적은 학습의 안정성을 위해 제외하거나 칼만 필터(Kalman Filter)로 보간(Interpolation)합니다.25  
* 속도 및 가속도 계산:

  $$v\_t \= \\frac{p\_t \- p\_{t-1}}{\\Delta t}, \\quad a\_t \= \\frac{v\_t \- v\_{t-1}}{\\Delta t}$$

  여기서 $\\Delta t$는 프레임 간격(SDD의 경우 30fps이나, 통상 2.5fps 등으로 다운샘플링하여 사용)입니다.15  
* **입력 텐서 구성:** 각 에이전트 $i$에 대해 시간 $t$에서의 상태 벡터 $S\_{i,t} \= \[x, y, v\_x, v\_y, a\_x, a\_y, \\text{class\_onehot}\]$를 생성합니다.

## ---

**5\. 모델링 방법론 I: 시맨틱 씬 그래프 구축 (Semantic Scene Graph)**

본 연구의 핵심 차별점은 에이전트 간의 관계를 단순한 거리가 아닌 '의미론적 타입'에 따라 정의하는 것입니다.

### **5.1 이기종 그래프(Heterogeneous Graph) 정의**

시간 $t$에서의 장면을 그래프 $\\mathcal{G}\_t \= (\\mathcal{V}\_t, \\mathcal{E}\_t)$로 정의합니다.

1\. 노드(Nodes)의 이질성:  
노드 집합 $\\mathcal{V}\_t$는 에이전트 타입에 따라 서로 다른 속성을 가집니다.

$$\\mathcal{V}\_t \= \\mathcal{V}\_{ped} \\cup \\mathcal{V}\_{biker} \\cup \\mathcal{V}\_{car} \\cup \\mathcal{V}\_{static}$$

* $\\mathcal{V}\_{static}$: 회전 교차로의 중앙 섬이나 횡단보도와 같은 환경 요소를 정적 노드로 포함하여, 에이전트가 환경 제약(도로 경계 등)을 인지하도록 합니다.5

2\. 엣지(Edges)의 다중 관계(Multi-Relational):  
엣지 집합 $\\mathcal{E}\_t$는 노드 타입 쌍(Source Type, Target Type)에 따라 고유한 관계 타입(Relation Type) $r \\in \\mathcal{R}$을 가집니다.

* $r\_{pp}$ (Pedestrian-to-Pedestrian): 사회적 거리두기, 군중 흐름.  
* $r\_{cp}$ (Car-to-Pedestrian): 위협 및 양보 관계. 차량의 접근은 보행자의 이동을 멈추게 하는 강한 억제력을 가집니다.  
* $r\_{bc}$ (Biker-to-Car): Death Circle에서 가장 빈번하고 위험한 상호작용. 자전거가 차량 사이를 빠져나가는(Filtering) 행태를 모델링합니다.  
* $r\_{env}$ (Agent-to-Static): 에이전트가 도로의 곡률이나 경계를 따르는 제약 조건.

### **5.2 동적 엣지 연결 전략 (Dynamic Connectivity)**

모든 에이전트를 완전 연결(Fully Connected)하는 것은 계산 비용이 높고 노이즈를 유발합니다. 따라서 다음 조건에 따라 동적으로 엣지를 생성합니다.

1. **거리 기반 임계값:** $d(i, j) \< \\theta\_{dist}$ (예: 15m)인 경우 연결.  
2. **시야각(Field of View) 제한:** 에이전트의 진행 방향 벡터를 기준으로 $\\pm 60^\\circ$ 내에 있는 대상만 연결(후방의 에이전트는 전방 에이전트의 행동에 영향을 주지만, 반대는 약함).  
3. **타입별 우선순위:** $r\_{cp}$ (차량-\>보행자) 관계는 거리가 멀더라도($2\\theta\_{dist}$) 연결하여 차량의 잠재적 위협을 반영합니다.

## ---

**6\. 모델링 방법론 II: ST-HGNN 아키텍처 (Modeling)**

제안하는 모델 \*\*ST-HGNN (Spatio-Temporal Heterogeneous Graph Neural Network)\*\*은 크게 세 가지 블록으로 구성됩니다: (1) 이기종 공간 인코딩, (2) 시간적 진화 학습, (3) 확률적 경로 디코딩.

### **6.1 Block 1: Heterogeneous Spatial Encoding (HeteroGAT)**

공간적 상호작용을 학습하기 위해 **Heterogeneous Graph Attention Network**를 사용합니다. 일반적인 GAT와 달리, 엣지 타입(관계)별로 서로 다른 가중치 행렬을 학습합니다.3

PyTorch Geometric의 HeteroConv 모듈을 활용하여 구현합니다. 특정 관계 $r$ (예: Car-\>Ped)에 대한 노드 $i$의 임베딩 업데이트 수식은 다음과 같습니다:

$$h\_i^{(l+1)} \= \\sigma \\left( \\sum\_{r \\in \\mathcal{R}} \\sum\_{j \\in \\mathcal{N}\_r(i)} \\alpha\_{ij}^{(r)} \\mathbf{W}\_r h\_j^{(l)} \\right)$$

* $\\mathbf{W}\_r$: 관계 $r$에 특화된 학습 가능한 가중치 행렬. 이를 통해 "차량이 보행자에게 미치는 영향력"과 "보행자가 차량에 미치는 영향력"을 비대칭적으로 모델링할 수 있습니다.  
* $\\alpha\_{ij}^{(r)}$: 어텐션 계수(Attention Coefficient). 이웃 노드 $j$가 노드 $i$에게 얼마나 중요한지를 나타냅니다.

**구현 코드 예시 (PyTorch Geometric):**

Python

from torch\_geometric.nn import HeteroConv, GATConv

\# 엣지 타입별로 서로 다른 GATConv 레이어 정의  
conv \= HeteroConv({  
    ('car', 'yield', 'ped'): GATConv((-1, \-1), 64, add\_self\_loops=False),  
    ('biker', 'overtake', 'car'): GATConv((-1, \-1), 64, add\_self\_loops=False),  
    ('ped', 'avoid', 'ped'): GATConv((-1, \-1), 64, add\_self\_loops=False),  
}, aggr='sum')

### **6.2 Block 2: Temporal Evolution (A3TGCN)**

공간적 특징이 추출된 후, 시간적 변화를 학습하기 위해 \*\*A3TGCN (Attention Temporal Graph Convolutional Network)\*\*을 적용합니다.4 A3TGCN은 시퀀스 데이터에서 각 타임스텝의 중요도를 동적으로 조절하는 시간 어텐션 메커니즘을 포함하고 있습니다.

* **입력:** $T\_{obs}$ 길이의 공간 임베딩 시퀀스 $\\mathbf{X} \\in \\mathbb{R}^{N \\times T\_{obs} \\times F}$.  
* **동작 원리:** GRU나 LSTM과 같은 순환 신경망 구조에 그래프 연산을 결합하되, 어텐션을 통해 과거의 특정 시점(예: 자전거가 급회전을 시작한 $t-3$ 시점)에 더 큰 가중치를 부여합니다. 이는 Death Circle과 같이 급격한 속도 변화가 잦은 환경에서 유용합니다.

### **6.3 Block 3: Probabilistic Decoding (Bivariate Gaussian)**

미래 경로는 불확실성을 내포하므로, 단일 좌표 $(x, y)$ 대신 이변량 가우스 분포(Bivariate Gaussian Distribution)의 파라미터를 예측합니다.26

* **출력:** 각 타임스텝 $t$에 대해 5개의 파라미터 $(\\mu\_x, \\mu\_y, \\sigma\_x, \\sigma\_y, \\rho)$.  
  * $\\mu\_x, \\mu\_y$: 예측 위치의 평균.  
  * $\\sigma\_x, \\sigma\_y$: 불확실성(표준편차).  
  * $\\rho$: x와 y 좌표 간의 상관계수.  
* 손실 함수 (Loss Function): 음의 로그 우도(Negative Log-Likelihood, NLL)를 최소화하도록 학습합니다.

  $$\\mathcal{L}\_{NLL} \= \- \\sum\_{t=T\_{obs}+1}^{T\_{pred}} \\log P(Y\_t | \\mu\_t, \\Sigma\_t)$$

## ---

**7\. Plan B: 안전 지표 분석 (Safety Analytics Layer)**

딥러닝 모델의 예측값은 확률적이므로, 실제 자율주행 시스템 적용 시에는 결정론적인 안전성 평가가 수반되어야 합니다. 본 연구는 예측된 궤적을 바탕으로 잠재적 사고 위험을 정량화하는 **Plan B 레이어**를 제안합니다.

### **7.1 Time-to-Collision (TTC) 분석**

TTC는 두 에이전트가 현재 속도를 유지한다고 가정할 때 충돌까지 남은 시간을 의미합니다.8

$$TTC \= \\frac{|| \\mathbf{p}\_j \- \\mathbf{p}\_i ||^2}{- (\\mathbf{p}\_j \- \\mathbf{p}\_i) \\cdot (\\mathbf{v}\_j \- \\mathbf{v}\_i) }$$

예측된 미래 궤적의 모든 쌍(Pair)에 대해 TTC를 계산하고, 임계값(예: 1.5초) 미만인 경우를 '근접 사고(Near-miss)'로 분류하여 경고를 생성합니다. 특히 Death Circle 내에서는 자전거와 차량 간의 TTC가 급격히 감소하는 구간을 식별하는 것이 중요합니다.

### **7.2 Post-Encroachment Time (PET) 분석**

PET는 선행 에이전트가 특정 충돌 영역(Conflict Zone)을 빠져나간 시점($t\_{exit}^i$)과 후행 에이전트가 해당 영역에 진입한 시점($t\_{entry}^j$)의 차이입니다.9

$$PET \= | t\_{entry}^j \- t\_{exit}^i |$$

이는 교차로에서 꼬리물기나 급작스러운 끼어들기 위험을 평가하는 데 효과적입니다. 학습된 모델이 생성한 궤적이 낮은 PET 값을 보인다면, 이는 모델이 공격적인 운전 성향을 학습했음을 의미할 수 있습니다.

### **7.3 영역 기반 위반 검사 (Region Violation Check)**

호모그래피로 변환된 맵에서 주행 불가능 영역(Non-drivable Area, 예: 중앙 화단)을 정의하고, 예측 궤적의 해당 영역 침범 여부를 검사합니다. 이는 모델이 물리적 제약을 준수하는지(Scene Compliance)를 평가하는 지표로 활용됩니다.5

## ---

**8\. 연구 로드맵 및 실행 계획 (Implementation Roadmap)**

### **Phase 1: 기반 조성 및 데이터 전처리 (1주 \~ 2주)**

* **작업:** SDD 원본 비디오 다운로드 및 Death Circle 프레임 추출.  
* **핵심:** 위성 지도 매칭을 통한 호모그래피 행렬($H$) 산출 및 검증. 픽셀 좌표의 미터 좌표 변환 데이터셋 구축 (.pkl 또는 .csv 포맷).  
* **도구:** OpenCV, QGIS, Python Pandas.

### **Phase 2: 모델 구현 및 학습 (3주 \~ 6주)**

* **작업:** PyTorch Geometric을 활용한 데이터 로더(DataLoader) 구현. HeteroData 객체 설계.  
* **모델링:** HeteroGAT 및 A3TGCN 모듈 코딩. 엣지 타입별 메시지 패싱 로직 구현.  
* **학습:** Baseline 모델(Social-LSTM, Trajectron++)과의 비교 학습 수행. Hyperparameter 튜닝.

### **Phase 3: 평가 및 안전 지표 분석 (7주 \~ 8주)**

* **정량 평가:** ADE(Average Displacement Error), FDE(Final Displacement Error) 산출.15  
* **안전 평가:** traja 또는 trajectory\_toolkit 라이브러리를 활용하여 예측 궤적의 TTC, PET 분포 분석.8

### **Phase 4: 시각화 및 최종 보고 (9주 \~ 10주)**

* **결과 시각화:** 위성 지도 위에 Ground Truth와 예측 궤적을 오버레이. 불확실성 타원(Uncertainty Ellipse) 시각화.  
* **위험 지도(Risk Map) 생성:** Death Circle 내에서 충돌 위험도가 높게 예측된 구역을 히트맵(Heatmap)으로 표현.27

## ---

**9\. 결과 시각화 및 기대 효과 (Visualization Strategy)**

### **9.1 예측 결과 시각화**

단순한 선(Line)으로 궤적을 표현하는 것을 넘어, 모델의 확신도를 표현하기 위해 **가우시안 불확실성 타원**을 시각화합니다.

* **배경:** 호모그래피 역변환을 통해 미터 좌표계의 예측 결과를 다시 원본 비디오 프레임 위에 투영합니다.  
* **범례:** 차량(빨강), 자전거(파랑), 보행자(초록) 등 에이전트 타입별로 색상을 구분하고, 점선으로 예측 경로를, 실선으로 실제 경로를 표시합니다.

### **9.2 위험도 히트맵 (Safety Heatmap)**

전체 테스트 시퀀스에 대해 TTC가 임계값 이하로 떨어진 지점들의 좌표를 누적하여 **공간 위험도 히트맵**을 생성합니다. 이는 Death Circle 내에서 구조적으로 위험한 '핫스팟'을 시각적으로 드러내며, 자율주행 차량이 해당 구역 진입 시 주의 수준을 높여야 함을 시사합니다.

## ---

**10\. 결론 (Conclusion)**

본 연구 계획서는 SDD Death Circle이라는 고난이도 혼합 교통 환경에서 이기종 에이전트의 경로를 정밀하게 예측하기 위한 포괄적인 솔루션을 제시합니다. 호모그래피를 통한 물리적 공간으로의 엄밀한 변환, 시맨틱 씬 그래프를 통한 관계론적 모델링, 그리고 GNN 기반의 시공간 학습은 기존 모델의 한계를 극복할 것입니다. 또한, Plan B로 제시된 안전 지표 분석은 단순한 알고리즘 성능 향상을 넘어, 실제 교통 안전 시스템에 적용 가능한 실질적인 인사이트를 제공할 것입니다. 이 연구는 향후 자율주행 차량의 판단/제어 모듈과 스마트 시티의 교통 관제 시스템을 위한 핵심 기술로 활용될 수 있습니다.

## ---

**상세 기술 부록 (Technical Appendix)**

### **A.1 하드웨어 및 소프트웨어 요구사항**

* **GPU:** NVIDIA RTX 3090 또는 A100 (대규모 그래프 배치 처리를 위해 24GB 이상 VRAM 권장).  
* **Framework:** PyTorch 2.0+, PyTorch Geometric (PyG), PyTorch Geometric Temporal.  
* **Library:** OpenCV (영상처리), Traja (궤적 분석), NetworkX (그래프 시각화).

### **A.2 예상되는 한계 및 극복 방안**

* **호모그래피 오차:** 평면 가정으로 인해 키가 큰 물체(버스 등)의 상단 좌표에 오차가 발생할 수 있음. \-\> 바운딩 박스의 하단 중앙점을 기준으로 좌표 변환을 수행하여 지면 접점(Footprint)을 추적함으로서 오차 최소화.  
* **가림 현상(Occlusion):** 나무 등에 의해 에이전트가 가려지는 경우. \-\> A3TGCN의 시간적 기억 능력을 활용해 짧은 가림 구간을 보간하거나, 전처리 단계에서 선형 보간법 적용.

---

보고서 작성자: AI Research Specialist (Autonomous Systems Domain)  
작성일: 2025년 12월 14일

#### **참고 자료**

1. Stanford Drone Dataset: Multi-scale, Multi-target social navigation | Explore Technologies, 12월 14, 2025에 액세스, [https://techfinder.stanford.edu/technology/stanford-drone-dataset-multi-scale-multi-target-social-navigation](https://techfinder.stanford.edu/technology/stanford-drone-dataset-multi-scale-multi-target-social-navigation)  
2. GM3: A General Physical Model for Micro-Mobility Vehicles \- arXiv, 12월 14, 2025에 액세스, [https://arxiv.org/html/2510.07807v1](https://arxiv.org/html/2510.07807v1)  
3. torch\_geometric.nn.conv.HeteroConv — pytorch\_geometric documentation \- PyTorch Geometric, 12월 14, 2025에 액세스, [https://pytorch-geometric.readthedocs.io/en/2.7.0/generated/torch\_geometric.nn.conv.HeteroConv.html](https://pytorch-geometric.readthedocs.io/en/2.7.0/generated/torch_geometric.nn.conv.HeteroConv.html)  
4. PyTorch Geometric Temporal Documentation \- Read the Docs, 12월 14, 2025에 액세스, [https://pytorch-geometric-temporal.readthedocs.io/en/latest/modules/root.html](https://pytorch-geometric-temporal.readthedocs.io/en/latest/modules/root.html)  
5. TrajGNAS: Heterogeneous Multiagent Trajectory Prediction Based on a Graph Neural Architecture Search \- CVF Open Access, 12월 14, 2025에 액세스, [https://openaccess.thecvf.com/content/CVPR2025W/WAD/papers/Xu\_TrajGNAS\_Heterogeneous\_Multiagent\_Trajectory\_Prediction\_Based\_on\_a\_Graph\_Neural\_CVPRW\_2025\_paper.pdf](https://openaccess.thecvf.com/content/CVPR2025W/WAD/papers/Xu_TrajGNAS_Heterogeneous_Multiagent_Trajectory_Prediction_Based_on_a_Graph_Neural_CVPRW_2025_paper.pdf)  
6. A Review of Homography Estimation: Advances and Challenges \- MDPI, 12월 14, 2025에 액세스, [https://www.mdpi.com/2079-9292/12/24/4977](https://www.mdpi.com/2079-9292/12/24/4977)  
7. Basic concepts of the homography explained with code \- OpenCV Documentation, 12월 14, 2025에 액세스, [https://docs.opencv.org/4.x/d9/dab/tutorial\_homography.html](https://docs.opencv.org/4.x/d9/dab/tutorial_homography.html)  
8. traja \- PyPI, 12월 14, 2025에 액세스, [https://pypi.org/project/traja/](https://pypi.org/project/traja/)  
9. ethz-asl/trajectory\_toolkit: Python tool for analyzing and evaluating trajectory data \- GitHub, 12월 14, 2025에 액세스, [https://github.com/ethz-asl/trajectory\_toolkit](https://github.com/ethz-asl/trajectory_toolkit)  
10. Contrastive-Future-Trajectory-Prediction/README.md at main \- GitHub, 12월 14, 2025에 액세스, [https://github.com/lmb-freiburg/Contrastive-Future-Trajectory-Prediction/blob/main/README.md](https://github.com/lmb-freiburg/Contrastive-Future-Trajectory-Prediction/blob/main/README.md)  
11. stanford dataset · Issue \#36 · agrimgupta92/sgan \- GitHub, 12월 14, 2025에 액세스, [https://github.com/agrimgupta92/sgan/issues/36](https://github.com/agrimgupta92/sgan/issues/36)  
12. A Review and Efficient Implementation of Scene Graph Generation Metrics, 12월 14, 2025에 액세스, [https://openaccess.thecvf.com/content/CVPR2024W/SG2RL/papers/Lorenz\_A\_Review\_and\_Efficient\_Implementation\_of\_Scene\_Graph\_Generation\_Metrics\_CVPRW\_2024\_paper.pdf](https://openaccess.thecvf.com/content/CVPR2024W/SG2RL/papers/Lorenz_A_Review_and_Efficient_Implementation_of_Scene_Graph_Generation_Metrics_CVPRW_2024_paper.pdf)  
13. Heterogeneous Graph-based Trajectory Prediction using Local Map Context and Social Interactions \- arXiv, 12월 14, 2025에 액세스, [https://arxiv.org/html/2311.18553](https://arxiv.org/html/2311.18553)  
14. PyTorch Geometric Temporal Documentation \- Read the Docs, 12월 14, 2025에 액세스, [https://pytorch-geometric-temporal.readthedocs.io/en/latest/modules/root.html\#torch\_geometric\_temporal.nn.recurrent.attention.A3TGCN](https://pytorch-geometric-temporal.readthedocs.io/en/latest/modules/root.html#torch_geometric_temporal.nn.recurrent.attention.A3TGCN)  
15. M2Tames: Interaction and Semantic Context Enhanced Pedestrian Trajectory Prediction \- MDPI, 12월 14, 2025에 액세스, [https://www.mdpi.com/2076-3417/14/18/8497](https://www.mdpi.com/2076-3417/14/18/8497)  
16. Khrylx/Trajectron-plus-plus \- GitHub, 12월 14, 2025에 액세스, [https://github.com/Khrylx/Trajectron-plus-plus](https://github.com/Khrylx/Trajectron-plus-plus)  
17. Spatio-Temporal Heterogeneous Graph Neural Networks for Estimating Time of Travel, 12월 14, 2025에 액세스, [https://www.mdpi.com/2079-9292/12/6/1293](https://www.mdpi.com/2079-9292/12/6/1293)  
18. Relationship Prediction for Scene Graph Generation \- CS229: Machine Learning, 12월 14, 2025에 액세스, [https://cs229.stanford.edu/proj2019spr/report/8.pdf](https://cs229.stanford.edu/proj2019spr/report/8.pdf)  
19. benedekrozemberczki/pytorch\_geometric\_temporal: PyTorch Geometric Temporal: Spatiotemporal Signal Processing with Neural Machine Learning Models (CIKM 2021\) \- GitHub, 12월 14, 2025에 액세스, [https://github.com/benedekrozemberczki/pytorch\_geometric\_temporal](https://github.com/benedekrozemberczki/pytorch_geometric_temporal)  
20. datasets/SDD · master · Payal Kaklotar / Trajectory-Prediction-Pedestrian \- TU Clausthal, 12월 14, 2025에 액세스, [https://registry.gitlab.tu-clausthal.de/pka20/Trajectory-Prediction-Pedestrian/-/tree/master/datasets/SDD](https://registry.gitlab.tu-clausthal.de/pka20/Trajectory-Prediction-Pedestrian/-/tree/master/datasets/SDD)  
21. Calculate Homography with and without SVD \- Math Stack Exchange, 12월 14, 2025에 액세스, [https://math.stackexchange.com/questions/3509039/calculate-homography-with-and-without-svd](https://math.stackexchange.com/questions/3509039/calculate-homography-with-and-without-svd)  
22. MZHI/stanford\_drone\_dataset\_to\_semantic\_task: Method for adapting Stanford Drone Dataset for semantic segmentation task and transfer learning U-net \- GitHub, 12월 14, 2025에 액세스, [https://github.com/MZHI/stanford\_drone\_dataset\_to\_semantic\_task](https://github.com/MZHI/stanford_drone_dataset_to_semantic_task)  
23. How to change a pixel distance to meters? \- Stack Overflow, 12월 14, 2025에 액세스, [https://stackoverflow.com/questions/25279390/how-to-change-a-pixel-distance-to-meters](https://stackoverflow.com/questions/25279390/how-to-change-a-pixel-distance-to-meters)  
24. Homography \- And how to calculate it? | by Siddharth Agarwal | all things about robotics and computer vision | Medium, 12월 14, 2025에 액세스, [https://medium.com/all-things-about-robotics-and-computer-vision/homography-and-how-to-calculate-it-8abf3a13ddc5](https://medium.com/all-things-about-robotics-and-computer-vision/homography-and-how-to-calculate-it-8abf3a13ddc5)  
25. Stanford Drone Dataset \- Kaggle, 12월 14, 2025에 액세스, [https://www.kaggle.com/datasets/aryashah2k/stanford-drone-dataset](https://www.kaggle.com/datasets/aryashah2k/stanford-drone-dataset)  
26. Vehicle Trajectory Prediction Using Hierarchical Graph Neural Network for Considering Interaction among Multimodal Maneuvers \- MDPI, 12월 14, 2025에 액세스, [https://www.mdpi.com/1424-8220/21/16/5354](https://www.mdpi.com/1424-8220/21/16/5354)  
27. The Stanford Drone Dataset Is More Complex Than We Think: An Analysis of Key Characteristics \- ResearchGate, 12월 14, 2025에 액세스, [https://www.researchgate.net/publication/359927030\_The\_Stanford\_Drone\_Dataset\_is\_More\_Complex\_than\_We\_Think\_An\_Analysis\_of\_Key\_Characteristics](https://www.researchgate.net/publication/359927030_The_Stanford_Drone_Dataset_is_More_Complex_than_We_Think_An_Analysis_of_Key_Characteristics)